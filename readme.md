# Intelli3

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Ontology](https://img.shields.io/badge/Ontology-RDF%2FOWL-informational)
![SHACL](https://img.shields.io/badge/Validation-SHACL-informational)
![LLM](https://img.shields.io/badge/LLM-Ollama%20Chat-informational)

Intelli3 is a **Python-based research prototype** that analyzes educational resources (primarily **text**) and produces an **explainable “Multiple Intelligences” profile** by combining:
- **Ontology-driven modeling** (OntoMI in RDF/TTL),
- **LLM-based annotation** (via Ollama chat),
- **Evidence extraction** (e.g., YAKE candidates + contextual classification),
- **Validation** (SHACL constraints).

This repository is part of my **M.Sc. research in Computer Science**, supervised by **Prof. Sidgley Camargo de Andrade** and **Prof. Clodis Boscarioli**.

---

## Table of Contents

- [Intelli3](#intelli3)
- [Repository Structure](#repository-structure)
  - [High-level directories](#high-level-directories)
  - [Current root files (from your project snapshot)](#current-root-files-from-your-project-snapshot)
- [Pipeline Overview (Stages)](#pipeline-overview-stages)
- [Documentation (Module Readmes)](#documentation-module-readmes)
- [Directory Conventions](#directory-conventions)
- [How to Use (Batch Pipeline)](#how-to-use-batch-pipeline)
  - [What happens by default](#what-happens-by-default)
- [Installation](#installation)
  - [1) Python](#1-python)
  - [2) Core dependencies](#2-core-dependencies)
  - [3) spaCy models (if S1 is enabled)](#3-spacy-models-if-s1-is-enabled)
  - [4) LLM runtime (if S3 uses an LLM)](#4-llm-runtime-if-s3-uses-an-llm)
- [Quick Start](#quick-start)
  - [1) Put text files in `source/`](#1-put-text-files-in-source)
  - [2) Ensure the ontology is available](#2-ensure-the-ontology-is-available)
  - [3) Run the pipeline](#3-run-the-pipeline)
- [CLI Usage](#cli-usage)
  - [Basic](#basic)
  - [Turn steps on/off](#turn-steps-onoff)
- [Full Parameter Reference](#full-parameter-reference)
  - [Paths](#paths)
  - [S1 — Ingest (core options)](#s1--ingest-core-options)
  - [S1 — Segmentation and fallback splitting](#s1--segmentation-and-fallback-splitting)
  - [S1 — Title/Abstract detection](#s1--titleabstract-detection)
  - [S2 — RDF instantiation](#s2--rdf-instantiation)
  - [S3 — Evidences](#s3--evidences)
  - [S4 — Activations (threshold + weights)](#s4--activations-threshold--weights)
  - [S5 — MI profile vector](#s5--mi-profile-vector)
  - [S7 — SHACL validation](#s7--shacl-validation)
- [Outputs (per document)](#outputs-per-document)
- [Examples](#examples)
- [Outputs and telemetry](#outputs-and-telemetry)
- [Troubleshooting](#troubleshooting)
  - [“ontologia não encontrada”](#ontologia-não-encontrada)
  - [S3 fails with LLM / Ollama errors](#s3-fails-with-llm--ollama-errors)
  - [SHACL doesn’t conform](#shacl-doesnt-conform)
- [Intelli3 Classifier](#intelli3-classifier)
- [Intelli3 PoC Tests (classifier.tests)](#intelli3-poc-tests-classifiertests)
  - [What `python3 -m classifier.tests` runs by default](#what-python3--m-classifiertests-runs-by-default)
  - [CLI options (all supported commands)](#cli-options-all-supported-commands)
  - [Practical recipes](#practical-recipes)
  - [Which profiles exist?](#which-profiles-exist)

## Repository Structure

### High-level directories

- **`docs/`**  
  Documentation files (module-by-module readmes and technical notes).  
  The main index is: **[`docs/README.md`](docs/README.md)**

- **`source/`**  
  Input materials to be analyzed (texts and other supported resources you want the pipeline to process).

- **`output/`**  
  Pipeline outputs (artifacts generated by each stage: intermediate JSON/RDF, final vectors, reports, etc.).

### Current root files (from your project snapshot)

```text
.
├── docs/
├── output/
├── source/
├── evidences_api.py
├── evidences_api_helpers.py
├── ontomi.ttl
├── readme.md
├── run_batch.py
├── s1_ingest.py
├── s2_instantiate.py
├── s3_evidences.py
├── s4_activations.py
├── s5_profile_vector.py
├── s6_tests.py
└── s7_shacl_validate.py
````

---

## Pipeline Overview (Stages)

The pipeline is organized in sequential scripts:

1. **`s1_ingest.py`** — ingestion/preparation of raw inputs from `source/`
2. **`s2_instantiate.py`** — creates initial structured instances (often RDF entities / base metadata)
3. **`s3_evidences.py`** — extracts evidence candidates and assigns MI-related signals (calls `evidences_api.py`)
4. **`s4_activations.py`** — consolidates evidence into activation events (primary/secondary signals, scoring, etc.)
5. **`s5_profile_vector.py`** — computes the final MI vector/profile from activations
6. **`s6_tests.py`** — diagnostic/verification routines for experiments
7. **`s7_shacl_validate.py`** — validates generated RDF against SHACL shapes

`run_batch.py` is the orchestrator that typically runs stages in order over a batch of inputs.

---

## Documentation (Module Readmes)

All detailed docs live under **`docs/`**. Start here: **[`docs/README.md`](docs/README.md)**.

Planned per-file documentation pages (links you can keep in the main README):

* Core / LLM Evidence Layer

  * [`docs/evidences_api.md`](docs/evidences_api.md) — LLM-based evidence annotation (YAKE + Ollama + scoring)
  * [`docs/evidences_api_helpers.md`](docs/evidences_api_helpers.md) — helper utilities used by the evidence layer

* Ontology

  * [`docs/ontomi.md`](docs/ontomi.md) — OntoMI ontology file (`ontomi.ttl`), namespaces, main classes/properties

* Orchestration

  * [`docs/run_batch.md`](docs/run_batch.md) — batch execution, parameters, expected I/O

* Pipeline Stages

  * [`docs/s1_ingest.md`](docs/s1_ingest.md)
  * [`docs/s2_instantiate.md`](docs/s2_instantiate.md)
  * [`docs/s3_evidences.md`](docs/s3_evidences.md)
  * [`docs/s4_activations.md`](docs/s4_activations.md)
  * [`docs/s5_profile_vector.md`](docs/s5_profile_vector.md)
  * [`docs/s6_tests.md`](docs/s6_tests.md)
  * [`docs/s7_shacl_validate.md`](docs/s7_shacl_validate.md)

---

## Directory Conventions

* Put your raw materials in: **`source/`**
* Run the pipeline / batch scripts
* Collect results in: **`output/`**
* Keep demonstration runs and reproducible examples in: **`PoC/`**
* Keep all technical documentation in: **`docs/`**

---

## How to Use (Batch Pipeline)

Intelli3 is designed to be run in **batch mode** over `.txt` files placed in `source/`. The main entry point is:

- **`run_batch.py`** — orchestrates steps **S1 → S7** and writes outputs per document under `output/`.

### What happens by default

When you run:

```bash
python run_batch.py
````

the batch runner will:

1. Read all `.txt` files from `./source/`
2. Create an output folder per input: `./output/<slug_of_filename>/`
3. Execute the enabled steps (S1 → S7), respecting dependencies
4. Write step artifacts + telemetry (`run_log.json`)
5. Write a global `batch_report.json` under `./output/`

> **Step dependency rule (important):**
>
> * If **S2** is disabled, **S3..S7** won’t run.
> * If **S3** is disabled, **S4..S7** won’t run.
> * If **S4** is disabled, **S5..S7** won’t run.
> * If **S5** is disabled, **S6..S7** won’t run.
> * If **S6** is disabled, **S7** won’t run.

---

## Installation

### 1) Python

* **Python 3.10+** (recommended)

Create and activate a virtual environment:

```bash
python -m venv .venv
# Windows (PowerShell)
.venv\Scripts\Activate.ps1
# Linux/macOS
source .venv/bin/activate
```

### 2) Core dependencies

At minimum (typical for S2+ / RDF + SHACL):

```bash
pip install rdflib pyshacl
```

For ingest and text processing (S1) and evidence extraction (S3), you will likely also need:

```bash
pip install spacy unidecode yake ftfy clean-text requests
```

> **Note:** S1 uses your local module **`intelli3text`** (project-specific).
> Install it as your environment requires (e.g., editable install from your own repo):

```bash
pip install -e path/to/intelli3text
```

### 3) spaCy models (if S1 is enabled)

Install at least one spaCy model (choose one size you prefer):

```bash
python -m spacy download en_core_web_md
python -m spacy download pt_core_news_md
python -m spacy download es_core_news_md
```

If you use `--nlp-size lg`, install `*_lg` models instead.

### 4) LLM runtime (if S3 uses an LLM)

If your `evidences_api.py` uses Ollama:

1. Install Ollama (OS-specific)
2. Ensure it is running on the configured host (default is usually `http://127.0.0.1:11434`)
3. Pull your target model, e.g.:

```bash
ollama pull mistral:7b-instruct
```

---

## Quick Start

### 1) Put text files in `source/`

```bash
mkdir -p source
# put .txt files into ./source/
```

### 2) Ensure the ontology is available

`ontomi.ttl` must exist at project root (or pass `--onto <path>`).

### 3) Run the pipeline

```bash
python run_batch.py
```

---

## CLI Usage

### Basic

```bash
python run_batch.py --source-dir source --out-dir output
```

### Turn steps on/off

* `--no-s2` : disable S2 (and therefore S3..S7)
* `--no-s3` : disable S3 (and therefore S4..S7)
* `--no-s4` : disable S4 (and therefore S5..S7)
* `--no-s5` : disable S5 (and therefore S6..S7)
* `--no-s6` : disable S6 (and therefore S7)
* `--no-s7` : disable S7

Examples:

Run **only S1** (ingest JSON):

```bash
python run_batch.py --no-s2
```

Run **S1 + S2 only**:

```bash
python run_batch.py --no-s3
```

Run full pipeline but disable SHACL validation:

```bash
python run_batch.py --no-s7
```

---

## Full Parameter Reference

Below is a grouped reference for the most relevant parameters supported by the batch runner.

> Defaults shown here reflect the *expected* defaults described in the batch documentation.
> (If a default differs in code, the code is the source of truth.)

---

### Paths

* `--source-dir` (default: `source`)
  Folder containing `.txt` input documents.

* `--out-dir` (default: `output`)
  Output root folder. A subfolder is created per document.

---

### S1 — Ingest (core options)

These parameters affect how the raw text is cleaned, segmented, and annotated.

* `--lang-hint` (default: `None`, choices: `pt|en|es`)
  Forces/limits language handling to a single language. Useful if inputs are known to be only PT/EN/ES.

* `--cleaners` (default: `ftfy,clean_text,pdf_breaks`)
  Comma-separated list of cleaner passes (typically forwarded to `intelli3text`).
  Typical cleaners:

  * `ftfy`: fixes broken unicode / encoding artifacts
  * `clean_text`: general cleanup (whitespace, control chars, etc.)
  * `pdf_breaks`: mitigates line-break artifacts common in PDF exports

* `--lid-primary` (default: `fasttext`)
  Primary language identification engine used in S1.

* `--lid-fallback` (default: `none`)
  Optional fallback LID engine (e.g., `cld3`) or `none`.

* `--languages` (default: `pt,en,es`)
  Comma-separated list of supported languages for LID and downstream processing.

* `--nlp-size` (default: `lg`, choices: `lg|md|sm`)
  Preferred spaCy model size:

  * `sm`: lightweight, fastest
  * `md`: balanced
  * `lg`: best accuracy, heavier

---

### S1 — Segmentation and fallback splitting

These parameters control paragraph segmentation and resegmentation fallback.

* `--paragraph-min-chars` (default: `30`)
  Minimum paragraph size kept as a valid paragraph.

* `--lid-min-chars` (default: `60`)
  Minimum paragraph length required to run language detection.

* `--split-max-chars` (default: `900`)
  Target chunk size when resegmenting long paragraphs.

* `--split-min-chars` (default: `120`)
  Minimum chunk size during resegmentation (very short chunks are merged).

* `--no-resegment`
  Disables the fallback resegmentation when a huge paragraph is detected.

---

### S1 — Title/Abstract detection

* `--force-title`
  Forces marking a paragraph as title/abstract (even if heuristics are uncertain).

* `--title-scan-k` (default: `3`)
  How many initial paragraphs are scanned as title/abstract candidates.

* `--title-max-chars` (default: `160`)
  Maximum number of characters for a paragraph to qualify as a title candidate.

---

### S2 — RDF instantiation

* `--onto` (default: `ontomi.ttl`)
  Path to the OntoMI ontology (TTL). Required for S2+.

* `--base-ns` (default: `None`)
  Base namespace for generated instances.
  If omitted, the pipeline may fall back to a namespace derived from `doc_id#`.

* `--s2-graph` (default: `full`)
  Graph content mode:

  * `full`: ontology + instances together
  * `instances`: instances only (lighter TTL)
  * `instances+imports`: instances plus `owl:imports` links

---

### S3 — Evidences

* `--s3-no-llm`
  Attempts to run S3 without LLM usage.
  Only works if your `evidences_api.py` implements a non-LLM fallback.

* `--s3-no-evokes`
  Prevents creating `onto:evokesIntelligence` links for evidences, even if available.
  Useful for ablation studies or to avoid biasing later stages.

---

### S4 — Activations (threshold + weights)

S4 computes activation scores per fragment/intelligence using evidence types and weights.

* `--theta` (default: `0.75`)
  Relative threshold for linking *secondary* intelligences per fragment.
  Higher = fewer secondaries; lower = more secondaries.

* `--w-keyword` (default: `1.00`)
  Weight for **Keyword** evidences.

* `--w-context` (default: `1.25`)
  Weight for **ContextObject** evidences.

* `--w-strategy` (default: `1.10`)
  Weight for **DiscursiveStrategy** evidences.

---

### S5 — MI profile vector

S5 builds profile vectors from activations, for fragments and/or documents.

* `--s5-scope` (default: `both`)
  Vector scope:

  * `document`: only a document-level vector
  * `fragment`: only per-fragment vectors
  * `both`: both document + fragment vectors

* `--s5-norm` (default: `l1`)
  Normalization:

  * `l1`: L1 normalization
  * `l2`: L2 normalization
  * `softmax`: softmax distribution (requires `--s5-tau`)

* `--s5-tau` (default: `1.0`)
  Softmax temperature (only used when `--s5-norm=softmax`).
  Lower values make distributions “sharper”; higher values make them “flatter”.

* `--alpha-title` (default: `1.30`)
  Weight multiplier for title/abstract paragraphs.

* `--alpha-body` (default: `1.00`)
  Weight multiplier for body paragraphs.

* `--s5-vec-places` (default: `4`)
  Decimal places written in vector scores.

* `--s5-no-mi-vector-string`
  Disables writing the percent-string representation (`onto:miVector`).

---

### S7 — SHACL validation

* `--s7-inference` (default: `rdfs`)
  Inference mode for pySHACL:

  * `none`
  * `rdfs`
  * `owlrl`

---

## Outputs (per document)

Each input document generates a folder:

`output/<doc_slug>/`

Typical artifacts:

* `s1_output.json`
* `instances_fragments.ttl`
* `instances_fragments_evidences.ttl`
* `evidences_payload.json`
* `scores_by_fragment.json`
* `instances_fragments_activations.ttl`
* `instances_fragments_profile.ttl`
* `cq1_evoked.txt`
* `cq2_elements_by_intel.txt`
* `cq3_top_intelligence.txt`
* `shacl_report.ttl`
* `shacl_report.txt`
* `run_log.json`

At output root:

* `output/batch_report.json`

---

## Examples

### Full pipeline, default settings

```bash
python run_batch.py
```

### Full pipeline, but disable LLM in S3

```bash
python run_batch.py --s3-no-llm
```

### Make the secondary linking stricter (fewer secondaries)

```bash
python run_batch.py --theta 0.90
```

### Use softmax normalization

```bash
python run_batch.py --s5-norm softmax --s5-tau 0.7
```

### Instances-only RDF graph (lighter TTL)

```bash
python run_batch.py --s2-graph instances
```

### Fully

```bash
python run_batch.py --source-dir source --out-dir output --lang-hint pt   --cleaners "ftfy,clean_text,pdf_breaks"   --lid-primary fasttext --lid-fallback none --languages "pt,en,es"   --nlp-size md --paragraph-min-chars 60 --lid-min-chars 60   --split-max-chars 900 --split-min-chars 250   --force-title --title-scan-k 5 --title-max-chars 160   --onto ontomi.ttl --s2-graph instances   --theta 0.75 --w-keyword 1.00 --w-context 1.25 --w-strategy 1.10   --s5-scope both --s5-norm l1 --s5-tau 1.0   --alpha-title 1.30 --alpha-body 1.00 --s5-vec-places 4   --s7-inference rdfs
```

### More lines

```bash
python run_batch.py --source-dir source --out-dir output --lang-hint pt   --cleaners "ftfy,clean_text,pdf_breaks"   --lid-primary fasttext --lid-fallback none --languages "pt,en,es"   --nlp-size md --paragraph-min-chars 20 --lid-min-chars 30   --split-max-chars 300 --split-min-chars 80   --force-title --title-scan-k 5 --title-max-chars 160   --onto ontomi.ttl --s2-graph instances   --theta 0.75 --w-keyword 1.00 --w-context 1.25 --w-strategy 1.10   --s5-scope both --s5-norm l1 --s5-tau 1.0   --alpha-title 1.30 --alpha-body 1.00 --s5-vec-places 4   --s7-inference rdfs
```

---

## Outputs and telemetry

For each document:

* `run_log.json` contains durations and per-step metrics
* `batch_report.json` aggregates outcomes for the whole run

Failures:

* If processing a file fails, its output folder will contain `s1_error.txt` and the batch continues.

---

## Troubleshooting

### “ontologia não encontrada”

If S2 is enabled, `--onto` must exist (default: `ontomi.ttl`).

### S3 fails with LLM / Ollama errors

If your `evidences_api.py` uses an LLM:

* Ensure the LLM runtime is up
* Ensure the target model is pulled/available
* Or run with `--s3-no-llm` (only if your evidences implementation supports it)

### SHACL doesn’t conform

Check `shacl_report.txt` and `shacl_report.ttl` in the document folder.

---

## Intelli3 Classifier

In addition to the semantic analysis pipeline, Intelli3 includes a **dedicated classification and recommendation module**, referred to as the **Intelli3 Classifier**.

This module operates **on top of the MI profile vectors** generated by the pipeline (S1–S5) and is responsible for:

* Ranking educational resources according to **reference cognitive profiles**;
* Supporting **focused recommendations** by selected Multiple Intelligences;
* Enabling **quantitative evaluation** of the model through stability and effectiveness metrics.

The classifier is **fully decoupled** from the ingestion, ontology instantiation, and evidence extraction stages. It consumes only the final MI vectors (RDF or numeric form), ensuring modularity, reproducibility, and experimental control.

As part of the **proof of concept** of this research, the classifier is used to assess:

* ranking stability (Spearman correlation),
* predictive effectiveness (F1 score),
* and robustness of the generated cognitive profiles across runs.

Together, the Intelli3 pipeline and the Intelli3 Classifier form a **complete, explainable, and research-oriented framework** for semantic classification and recommendation of educational resources grounded in the Theory of Multiple Intelligences.

---

# Intelli3 PoC Tests (classifier.tests)

This project includes a small CLI test runner that:

1. **Loads MIProfile vectors** from TTL files generated by the pipeline (typically under `output/<doc_id>/instances_fragments_profile.ttl`).
2. **Ranks loaded documents** by similarity against one or more **synthetic reference profiles** (P1…P11).

The entrypoint is:

```bash
python3 -m classifier.tests
```

---

## What `python3 -m classifier.tests` runs by default

If you run it **without arguments**, it uses these defaults:

* `--output output`
* `--filename instances_fragments_profile.ttl`
* `--profiles all`
* `--topk 10`

So it will:

* scan `output/**/instances_fragments_profile.ttl`
* load every document vector it can find
* rank documents for **all available profiles** (P1…P11)
* print the **top 10** docs for each profile

That means the tests you ran were **not “one profile only”** unless you explicitly passed `--profiles ...`.

---

## CLI options (all supported commands)

You can see the built-in help anytime:

```bash
python3 -m classifier.tests -h
```

### `--output <dir>`

Base directory to scan for TTLs (recursively).

Example:

```bash
python3 -m classifier.tests --output output/174
```

### `--filename <name.ttl>`

The TTL filename to look for inside each subfolder.

Default:

* `instances_fragments_profile.ttl`

Example:

```bash
python3 -m classifier.tests --output output --filename instances_fragments_profile.ttl
```

### `--limit <N>`

Loads only the first **N** documents (after discovery) to speed up testing.

Example:

```bash
python3 -m classifier.tests --output output --limit 25
```

### `--profiles <list|all>`

Which reference profiles to use for ranking.

* Use `all` (default) to run for every profile
* Or pass a comma-separated list: `P1-LING,P2-LOG,...`

Example:

```bash
python3 -m classifier.tests --output output --profiles P2-LOG
```

Example (multiple profiles):

```bash
python3 -m classifier.tests --output output --profiles P11-GLOB,P10-TEC,P9-HUM
```

### `--topk <K>`

How many ranked documents to print per profile.

Default:

* `10`

Example:

```bash
python3 -m classifier.tests --output output --topk 5
```

### `--only-load`

Only tests loading (parsing TTLs + extracting vectors).
**No ranking is performed.**

Example:

```bash
python3 -m classifier.tests --output output --only-load
```

### `--list-profiles`

Prints all available profile keys and exits.

Example:

```bash
python3 -m classifier.tests --list-profiles
```

---

## Practical recipes

### 1) Test a single doc folder (fast sanity check)

```bash
python3 -m classifier.tests --output output/174 --profiles P11-GLOB --topk 10
```

### 2) Just verify how many docs are being detected

```bash
python3 -m classifier.tests --output output --only-load
```

### 3) Run the full PoC-style ranking on everything

```bash
python3 -m classifier.tests --output output --profiles all --topk 10
```

### 4) Debug “why is it loading 0 documents?”

Usually one of these:

* wrong `--output` path
* TTL has a different filename than the default
* TTL does not contain a MIProfile + vector in any of the formats the loader supports

Use:

```bash
python3 -m classifier.tests --output output --only-load
```

and (if needed) point to the exact folder:

```bash
python3 -m classifier.tests --output output/174 --only-load
```

---

## Which profiles exist?

Use:

```bash
python3 -m classifier.tests --list-profiles
```

You should see keys like:

* `P1-LING`, `P2-LOG`, `P3-ESP`, `P4-CORP`, `P5-MUS`, `P6-INTER`, `P7-INTRA`, `P8-NAT`,
* `P9-HUM`, `P10-TEC`, `P11-GLOB`

---